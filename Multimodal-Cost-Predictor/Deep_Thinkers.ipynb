{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057442ca-935d-4d52-b90c-f526d3b2d76a",
   "metadata": {},
   "source": [
    "# Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e69bbe-5abc-4886-870a-d54016e3758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "# For data handling\n",
    "%pip install numpy pandas\n",
    "# For ML tasks, such as regression\n",
    "%pip install scikit-learn\n",
    "# For efficient modelling\n",
    "%pip install lightgbm xgboost\n",
    "# Deep Learning (PyTorch)\n",
    "%pip install torch torchvision\n",
    "# Advanced NLP\n",
    "%pip install transformers sentence-transformers\n",
    "# Image utilities\n",
    "%pip install Pillow requests tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbceba4-409f-4935-b973-7d50235e8f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed successfully.\n"
     ]
    }
   ],
   "source": [
    "# For verification purposes\n",
    "if \"ERROR:\" in output.stderr or \"Failed\" in output.stdout:\n",
    "    print(\"One or more packages failed to install\")\n",
    "else:\n",
    "    print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d3c0e-9f0e-47ef-a63e-595c66aee35c",
   "metadata": {},
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c8ff03-c77d-48cc-86ea-ab65dc33bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Current Working Directory set to: D:\\Jupyter_Projects\\ML_Challenge_Data\\68e8d1d70b66d_student_resource\\student_resource\n"
     ]
    }
   ],
   "source": [
    "# CORE DATA HANDLING & UTILITIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm # For tracking slow processes like downloads/feature extraction\n",
    "\n",
    "correct_path = r\"D:\\Jupyter_Projects\\ML_Challenge_Data\\68e8d1d70b66d_student_resource\\student_resource\" \n",
    "os.chdir(correct_path)\n",
    "print(f\"New Current Working Directory set to: {os.getcwd()}\")\n",
    "# FEATURE ENGINEERING: TEXT (NLP)\n",
    "# BEST PRACTICE: Focus on contextual embeddings (Transformers)\n",
    "\n",
    "# General HuggingFace Transformers for model/tokenizer loading\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# For superior sentence-level embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# FEATURE ENGINEERING: VISION (IMAGES)\n",
    "# BEST PRACTICE: Use a modern CNN (ResNet, EfficientNet) via transfer learning\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time # Good practice for handling retries/throttling during image download\n",
    "\n",
    "# PYTORCH, for easy transfer learning\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "\n",
    "# MODELING, EVALUATION, & PREPROCESSING\n",
    "# BEST PRACTICE: Use efficient gradient boosting & the required custom metric\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer # Quantile is good for log-transformed price\n",
    "import lightgbm as lgb \n",
    "import xgboost as xgb \n",
    "\n",
    "# For visualising various plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To define SMAPE for validation.\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# Defining the SMAPE metric\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / denominator) * 100 # Multiply by 100 for percentage\n",
    "\n",
    "# Use sklearn's make_scorer for CV/Grid Search\n",
    "SMAPE_scorer = make_scorer(smape, greater_is_better=False)\n",
    "\n",
    "\n",
    "# Helper function import\n",
    "from src.utils import download_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9549f-82e7-4c67-8a35-237a2e531f38",
   "metadata": {},
   "source": [
    "# Load the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b3dede-a8e5-40f2-9705-be34cd528249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id                                    catalog_content  \\\n",
      "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
      "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
      "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
      "3      55858  Item Name: Judeeâ€™s Blue Cheese Powder 11.25 oz...   \n",
      "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
      "\n",
      "                                          image_link  price  \n",
      "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
      "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
      "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
      "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
      "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde4bbc-aae7-486e-b6c6-396a782d6a6a",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df5dfdb-0c22-4e3b-9a57-99bf35060024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types and info about non-null counts\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   sample_id        75000 non-null  int64  \n",
      " 1   catalog_content  75000 non-null  object \n",
      " 2   image_link       75000 non-null  object \n",
      " 3   price            75000 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Data types and info about non-null counts\\n')\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ba712-cbeb-4ada-9698-ab14f382e69a",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "No null values which is excellent, no need for dropping or imputing them. <br>\n",
    "'catalog_content' and 'image_link' are objects, perfect for feature engineering <br>\n",
    "'price' is float, regression on price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19592b48-eee9-4fce-8d42-a2416b800576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of the training data\n",
      "\n",
      "           sample_id         price\n",
      "count   75000.000000  75000.000000\n",
      "mean   149841.917707     23.647654\n",
      "std     86585.346513     33.376932\n",
      "min         0.000000      0.130000\n",
      "25%     73845.750000      6.795000\n",
      "50%    150129.000000     14.000000\n",
      "75%    225040.250000     28.625000\n",
      "max    299438.000000   2796.000000\n"
     ]
    }
   ],
   "source": [
    "print('Descriptive statistics of the training data\\n')\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd669d7c-0605-4ae4-8c0f-ca0ca2494f6e",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "Mean of price 23.64 is much higher than the median 14 (50%)<br>\n",
    "Maximum price is 2796, this indicates the distribution is highly right-skewed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e515c4e-f06e-493f-a1a8-f7312767183c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the raw price\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(train_df['price'], kde=True)\n",
    "plt.title('Price Distribution (Raw)')\n",
    "\n",
    "# Distribution of the log-transformed price (CRITICAL STEP)\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(np.log1p(train_df['price']), kde=True) # Using np.log1p handles zero/near-zero values gracefully\n",
    "plt.title('Price Distribution (Log Transformed)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba309ee3-0160-4adc-ab1e-4b20dbe21037",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "The raw price distribution is highly skewed, hence a regression model trained on this data will lead to poor performance on the vast majority of low priced items <br>\n",
    "The Log transformed distribution resembles a symmetrical, near Gaussian-distribution, allowing the model to perform better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69afbe20-0328-4c77-b13a-5068d12ca62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Full Catalog Content Inspection ---\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Item Name: La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\\nValue: 72.0\\nUnit: Fl Oz\\n\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Item Name: Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\\nBullet Point 1: Original Butter Cookies: Classic butter cookies made with real butter\\nBullet Point 2: Variety Pack: Includes 4 boxes with 32 cookies total\\nBullet Point 3: Occasion Perfect: Delicious cookies for birthdays, weddings, anniversaries\\nBullet Point 4: Shareable Treats: Fun to give and enjoy with friends and family\\nBullet Point 5: Salerno Brand: Trusted brand of delicious butter cookies since 1925\\nValue: 32.0\\nUnit: Ounce\\n\n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Item Name: Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\\nBullet Point 1: Loaded with hearty long grain wild rice and vegetables\\nBullet Point 2: Full of hearty goodness\\nBullet Point 3: Single serve bowls\\nBullet Point 4: Easy to prepare mix\\nBullet Point 5: 0 grams trans fat\\nValue: 11.4\\nUnit: Ounce\\n\n",
      "3    Item Name: Judeeâ€™s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings and Salad Dressings - Great for Dips, Spreads and Sauces - Made in USA\\nBullet Point 1: Add to your favorite appetizers, dips & spreads. Use to season popcorn or warmed pita chips.\\nBullet Point 2: Sprinkle over french fries, fried chicken, mashed potatoes, roasted veggies, pasta, and more\\nBullet Point 3: Made in a dedicated gluten-free facility and shipped in a standup, resealable pouch to ensure freshness\\nBullet Point 4: Ingredients: Blue Cheese (Milk, Salt, Cultures, & Enzymes) and Disodium Phosphate\\nBullet Point 5: Since 2009, Judeeâ€™s has been dedicated to providing fresh, allergy-conscious ingredients, great for your recipes and even better for your family\\nProduct Description: Judees Powdered Blue Cheese cheddar cheese powder is an alternative to mozzarella cheese shredded or american cheese slices deli. Make your own alfredo sauce with heavy cream and black buffalo dip with this powder. It adds extra flavor to salad dressing like ranch dressing and great on pizza dough or cauliflower pasta. Add to macaroni and cheese or popcorn seasoning for more aroma and cheesy feel. Combine with mustard and other ingredients to create your own dressing for buffalo chicken or buffalo wings.\\nValue: 11.25\\nUnit: Ounce\\n\n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Item Name: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\\nBullet Point: kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\\nValue: 12.0\\nUnit: Count\\n\n",
      "Name: catalog_content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the option to display the full content of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print a few rows of the catalog_content to inspect the full text\n",
    "print(\"--- Full Catalog Content Inspection ---\")\n",
    "print(train_df['catalog_content'].head())\n",
    "\n",
    "# Reset the option afterward (good practice)\n",
    "# pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c9e6e-be79-4ee4-9bf0-ea01864cce26",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "The data format is consistent with: <br>\n",
    "Item Name: text <br> \n",
    "Bullet Point 1...X: text <br>\n",
    "Value: number<br>\n",
    "Unit: unit-name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b99592-59aa-42cb-af4e-1aa32f52a2d6",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b3540-a212-47a6-9499-777410891393",
   "metadata": {},
   "source": [
    "## Adding a new target column (log_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ad605eb-69a7-4146-85d6-da1b5c1cf53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 original prices:\n",
      "0     4.89\n",
      "1    13.12\n",
      "2     1.97\n",
      "3    30.34\n",
      "4    66.49\n",
      "Name: price, dtype: float64\n",
      "\n",
      "First 5 log-transformed prices (our new target):\n",
      "0    1.773256\n",
      "1    2.647592\n",
      "2    1.088562\n",
      "3    3.444895\n",
      "4    4.211979\n",
      "Name: log_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# log-transformation on the target price column\n",
    "train_df['log_price'] = np.log1p(train_df['price'])\n",
    "\n",
    "# For verification: Printing the first few original & transformed values\n",
    "print(\"First 5 original prices:\")\n",
    "print(train_df['price'].head())\n",
    "print(\"\\nFirst 5 log-transformed prices (our new target):\")\n",
    "print(train_df['log_price'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807c163-2e34-4ba0-b388-a90685374969",
   "metadata": {},
   "source": [
    "## Adding new columns: base_value, base_unit, item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9a44b94-1f99-4e50-94e7-65bd3e64e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Normalized Base Unit Check (Top 5) ---\n",
      "\n",
      "--- Base Unit After Binning into 'Other' ---\n",
      "base_unit_binned\n",
      "Ounce/FlOz    55341\n",
      "Count         18267\n",
      "None            940\n",
      "Pound           240\n",
      "Other           212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Base Units:\n",
      "base_unit\n",
      "Ounce/FlOz    55341\n",
      "Count         18267\n",
      "None            940\n",
      "Pound           240\n",
      "Gram             43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract Base Value\n",
    "def extract_base_value(text):\n",
    "    \"\"\"Extracts the numerical 'Value' field.\"\"\"\n",
    "    if pd.isna(text): return None\n",
    "    # Pattern: 'Value: ' followed by a number (including decimals)\n",
    "    match = re.search(r'Value: ([\\d.]+)', str(text))\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# 2. Extract Base Unit\n",
    "def extract_base_unit(text):\n",
    "    \"\"\"Extracts the categorical 'Unit' field.\"\"\"\n",
    "    if pd.isna(text): return 'Unknown'\n",
    "    # Pattern: 'Unit: ' followed by one or more word characters\n",
    "    match = re.search(r'Unit: (\\w+)', str(text))\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return 'Unknown'\n",
    "\n",
    "# Function to normalize unit categories\n",
    "# --- FINAL ROBUST UNIT NORMALIZATION FUNCTION ---\n",
    "def normalize_unit(unit):\n",
    "    if pd.isna(unit):\n",
    "        return 'Unknown'\n",
    "    unit = unit.lower().strip()\n",
    "    \n",
    "    # 1. Volume/Weight Normalization\n",
    "    if unit in ['oz', 'ounce', 'fl oz', 'fl', 'fluid']:\n",
    "        return 'Ounce/FlOz'\n",
    "    if unit in ['lb', 'pound', 'pounds', 'lbs']: # <--- ADDED 'lbs'\n",
    "        return 'Pound'\n",
    "    if unit in ['g', 'gram', 'grams']:\n",
    "        return 'Gram'\n",
    "    if unit in ['l', 'liter', 'quart']:\n",
    "        return 'Liter'\n",
    "    if unit in ['ml', 'millilitre', 'milliliter']:\n",
    "        return 'Milliliter'\n",
    "    \n",
    "    # 2. Count/Discrete Item Normalization\n",
    "    if unit in ['count', 'ct', 'pcs', 'ea', 'pac', 'packet', 'pk', 'pack']: # <--- ADDED 'ea', 'pac', 'packet'\n",
    "        return 'Count'\n",
    "    \n",
    "    # 3. Handle 'none' and everything else for THRESHOLD_COUNT to bin\n",
    "    if unit == 'none':\n",
    "        return 'None'\n",
    "    \n",
    "    return unit # Returns the raw unit for the binning step to catch\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Normalized Base Unit Check (Top 5) ---\")\n",
    "train_df['base_value'] = train_df['catalog_content'].apply(extract_base_value)\n",
    "train_df['base_unit'] = train_df['catalog_content'].apply(extract_base_unit)\n",
    "train_df['base_unit'] = train_df['base_unit'].apply(normalize_unit)\n",
    "\n",
    "# Define a threshold for \"Other\" category (e.g., any unit with less than 200 occurrences)\n",
    "# Based on the output: pound=202, fluid=53, gram=39, etc.\n",
    "THRESHOLD_COUNT = 200 \n",
    "\n",
    "# Get the value counts\n",
    "unit_counts = train_df['base_unit'].value_counts()\n",
    "\n",
    "# Identify units to be binned into 'Other'\n",
    "low_frequency_units = unit_counts[unit_counts < THRESHOLD_COUNT].index\n",
    "\n",
    "# Apply the binning\n",
    "train_df['base_unit_binned'] = train_df['base_unit'].apply(\n",
    "    lambda x: 'Other' if x in low_frequency_units else x\n",
    ")\n",
    "\n",
    "print(\"\\n--- Base Unit After Binning into 'Other' ---\")\n",
    "print(train_df['base_unit_binned'].value_counts().head(10))\n",
    "print(\"\\nTop 5 Base Units:\")\n",
    "print(train_df['base_unit'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c25862d-4c8a-4a25-a350-96dc95d9a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Item Name Check\n",
      "0                                                                                                      La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)\n",
      "1                                                                                            Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)\n",
      "2                                                                                 Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)\n",
      "3    Judeeâ€™s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings and Salad Dressings - Great for Dips, Spreads and Sauces - Made in USA\n",
      "4                                                                                                         kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.\n",
      "Name: item_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def extract_item_name(text):\n",
    "    \"\"\"\n",
    "    Extracts the Item Name by capturing everything after 'Item Name:'\n",
    "    up to the first newline (\\n), which is a robust delimiter in this catalog structure.\n",
    "    \"\"\"\n",
    "    if pd.isna(text): \n",
    "        return None\n",
    "    \n",
    "    text = str(text)\n",
    "\n",
    "    # Pattern: 'Item Name: ' followed by any characters (non-greedy, .*?) until a newline or end of string\n",
    "    # We use re.search and then manually split to get the first line\n",
    "    match = re.search(r'Item Name: (.*)', text, re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        # Get the captured string (everything after 'Item Name:')\n",
    "        full_string = match.group(1)\n",
    "        \n",
    "        # Split by newline and take the first line (the item name)\n",
    "        item_name = full_string.split('\\n')[0].strip()\n",
    "        \n",
    "        # Clean up any trailing commas, if any remain\n",
    "        return item_name.rstrip(',')\n",
    "        \n",
    "    return None\n",
    "\n",
    "# Apply the function to see the improved result\n",
    "train_df['item_name'] = train_df['catalog_content'].apply(extract_item_name)\n",
    "\n",
    "print(\"Extracted Item Name Check\")\n",
    "print(train_df['item_name'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cb932-87e3-45ec-ae3f-bf8b39c0323d",
   "metadata": {},
   "source": [
    "## Creating item_pack_quantity column & cleaned_text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1af8f498-5910-44c6-b4df-cfce4b0afb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Pack Quantity (IPQ)\n",
      "0     6\n",
      "1     4\n",
      "2     6\n",
      "3     1\n",
      "4    12\n",
      "Name: item_pack_quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " IPQ Pattern:\n",
    " 1. Finds 'X' followed by common packaging terms (pack, case, ct, etc.) \n",
    " 2. Finds the common e-commerce phrases 'pack of X' and 'X per case'\n",
    " 3. Finds the number BEFORE 'per case' or 'per pack'\n",
    "'''\n",
    "IPQ_PATTERN = r'(\\d+)\\s*(?:per\\s*case|per\\s*pack)|(?:pack of|per\\s*case)\\s*(\\d+)|(\\d+)\\s*\\b(?:pack|count|pcs|ct|case|box)\\b'\n",
    "\n",
    "def extract_ipq(text):\n",
    "    \"\"\"Extracts the number of items/quantity from a text string, defaulting to 1.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 1\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Try to find a match using the final pattern\n",
    "    # We look for matches across all three capturing groups\n",
    "    matches = re.findall(IPQ_PATTERN, text)\n",
    "    \n",
    "    # Prioritize the largest number found, as this is often the total pack quantity.\n",
    "    max_ipq = 1\n",
    "    for m in matches:\n",
    "        # Check all three groups and take the non-empty string\n",
    "        for num_str in m:\n",
    "            if num_str:\n",
    "                try:\n",
    "                    num = int(num_str)\n",
    "                    if num > max_ipq:\n",
    "                        max_ipq = num\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    return max_ipq # Default remains 1 if nothing is found\n",
    "\n",
    "\n",
    "train_df['item_pack_quantity'] = train_df['catalog_content'].apply(extract_ipq)\n",
    "print(\"Item Pack Quantity (IPQ)\")\n",
    "print(train_df['item_pack_quantity'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f137f6f-f56c-401a-9239-b71735022858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   item name: la victoria green taco sauce mild, 12 ounce (pack of 6) value: 72.0 unit: fl oz\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               item name: salerno cookies, the original butter cookies, 8 ounce (pack of 4) bullet point 1: original butter cookies: classic butter cookies made with real butter bullet point 2: variety pack: includes 4 boxes with 32 cookies total bullet point 3: occasion perfect: delicious cookies for birthdays, weddings, anniversaries bullet point 4: shareable treats: fun to give and enjoy with friends and family bullet point 5: salerno brand: trusted brand of delicious butter cookies since 1925 value: 32.0 unit: ounce\n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      item name: bear creek hearty soup bowl, creamy chicken with rice, 1.9 ounce (pack of 6) bullet point 1: loaded with hearty long grain wild rice and vegetables bullet point 2: full of hearty goodness bullet point 3: single serve bowls bullet point 4: easy to prepare mix bullet point 5: 0 grams trans fat value: 11.4 unit: ounce\n",
      "3    item name: judee s blue cheese powder 11.25 oz gluten free and nut free use in seasonings and salad dressings great for dips, spreads and sauces made in usa bullet point 1: add to your favorite appetizers, dips spreads. use to season popcorn or warmed pita chips. bullet point 2: sprinkle over french fries, fried chicken, mashed potatoes, roasted veggies, pasta, and more bullet point 3: made in a dedicated gluten free facility and shipped in a standup, resealable pouch to ensure freshness bullet point 4: ingredients: blue cheese (milk, salt, cultures, enzymes) and disodium phosphate bullet point 5: since 2009, judee s has been dedicated to providing fresh, allergy conscious ingredients, great for your recipes and even better for your family product description: judees powdered blue cheese cheddar cheese powder is an alternative to mozzarella cheese shredded or american cheese slices deli. make your own alfredo sauce with heavy cream and black buffalo dip with this powder. it adds extra flavor to salad dressing like ranch dressing and great on pizza dough or cauliflower pasta. add to macaroni and cheese or popcorn seasoning for more aroma and cheesy feel. combine with mustard and other ingredients to create your own dressing for buffalo chicken or buffalo wings. value: 11.25 unit: ounce\n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       item name: kedem sherry cooking wine, 12.7 ounce 12 per case. bullet point: kedem sherry cooking wine, 12.7 ounce 12 per case. value: 12.0 unit: count\n",
      "Name: clean_catalog_content, dtype: object\n",
      "Cleaned Catalog Content created.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans text for Transformer input by normalizing and removing noise.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Replace newlines with spaces\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove characters that aren't letters, numbers, or standard punctuation\n",
    "    text = re.sub(r'[^a-z0-9\\s.,?!:;\\'\"()_]', ' ', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "train_df['clean_catalog_content'] = train_df['catalog_content'].apply(clean_text)\n",
    "print(train_df['clean_catalog_content'].head())\n",
    "print(\"Cleaned Catalog Content created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad962c-b56d-45e8-a1f2-c5f1be457c77",
   "metadata": {},
   "source": [
    "## Generate text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d48c4a40-83e5-4075-b1a4-26ee19e4d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f337dad5cfb24e25bb9e9c11857d84db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yella\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yella\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46905e3a0294eb385a660398c7ca943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d815ab509064c64975e511c212e6f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3848c644541b4e2095ced84929a53e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deef57f16ca94e1da0722124fb43064a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f5dde8005046cf9b26337b76799d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4981cf01737435aa86df99e0ee9d874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0ad3f0d6e144218c7869e6858b3331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee63ddf7afd456483c956fbc534bb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f67aadc699424bb1e4edd1dd98062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c17def417b4c8b9bac8adcc9c7c134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Text Embeddings (NLP) ---\n",
      "Converting text data into high-dimensional numerical vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536da958dc424d9d8a4bcc1cbe5b4308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text embeddings generated successfully.\n",
      "Shape of embeddings: (75000, 384)\n",
      "Each product's description is now represented by a 384-dimensional vector.\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 'all-MiniLM-L6-v2' model for efficiency and performance\n",
    "model_name = 'all-MiniLM-L6-v2' \n",
    "\n",
    "print(f\"Loading Sentence Transformer model: {model_name}...\")\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Use the cleaned text column\n",
    "text_data = train_df['clean_catalog_content'].tolist()\n",
    "\n",
    "print(\"\\n--- Generating Text Embeddings (NLP) ---\")\n",
    "print(\"Converting text data into high-dimensional numerical vectors...\")\n",
    "\n",
    "# Encode the text data. This is a resource-intensive step.\n",
    "train_embeddings = model.encode(text_data, \n",
    "                                show_progress_bar=True, \n",
    "                                convert_to_numpy=True,\n",
    "                                batch_size=32) # Using a batch size for efficiency\n",
    "\n",
    "embedding_dim = train_embeddings.shape[1]\n",
    "\n",
    "print(f\"\\nText embeddings generated successfully.\")\n",
    "print(f\"Shape of embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Each product's description is now represented by a {embedding_dim}-dimensional vector.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91b4826b-74af-436b-85fe-022cebfb08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model: all-mpnet-base-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9506add3892430494b338e54b4344db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yella\\Anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yella\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ae972416a4484ebcb16fa97ae2370d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2797d708a24472a847d6014cf612d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de8a799e13e4be3ae72778b5b32b2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b8c125693d44adbdafe37c80253b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95bdbed26234c2db64a5949dbab50fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdeac59fc5644e2b154346cc175c780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661555fb2fb24688803e56ea425bae74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02c7dbf526d4eba926640a1dd8cade5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabf822eedaa4befa70294536ab3fa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232e088dfb584febaf33f37058c32f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Text Embeddings (NLP) ---\n",
      "Converting text data into high-dimensional numerical vectors...\n",
      "\n",
      "Text embeddings generated successfully.\n",
      "Shape of embeddings: (75000, 384)\n",
      "Each product's description is now represented by a 384-dimensional vector.\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 'all-mpnet-base-v2' model now for richer semantic understanding\n",
    "model_name = 'all-mpnet-base-v2' \n",
    "\n",
    "print(f\"Loading Sentence Transformer model: {model_name}...\")\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Use the cleaned text column\n",
    "text_data = train_df['clean_catalog_content'].tolist()\n",
    "\n",
    "print(\"\\n--- Generating Text Embeddings (NLP) ---\")\n",
    "print(\"Converting text data into high-dimensional numerical vectors...\")\n",
    "\n",
    "# Encode the text data. This is a resource-intensive step.\n",
    "train_embeddings_mpnet = model.encode(text_data,  \n",
    "                                convert_to_numpy=True,\n",
    "                                batch_size=32) # Using a batch size for efficiency\n",
    "\n",
    "embedding_dim_mpnet = train_embeddings.shape[1]\n",
    "\n",
    "print(f\"\\nText embeddings generated successfully.\")\n",
    "print(f\"Shape of embeddings: {train_embeddings.shape}\")\n",
    "print(f\"Each product's description is now represented by a {embedding_dim}-dimensional vector.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d47bee-ca78-4e5c-8f54-c7a592a292fd",
   "metadata": {},
   "source": [
    "## Ensemble step:\n",
    "Combine the embeddings from diverse models giving our model multiple sematic perspectives <br>\n",
    "This leads to better generalization and consequently higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b1a4452-f58d-47c6-942a-6a541d50295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both sets of text embeddings saved successfully\n",
      "Concatenated Text Feature Shape: (75000, 1152)\n",
      "Total dimensionality of the text feature: 1152\n"
     ]
    }
   ],
   "source": [
    "# Save the embeddings generated by both models\n",
    "os.makedirs('embeddings', exist_ok = True)\n",
    "# Save concatenated embeddings for all-MiniLM-L6-v2\n",
    "# np.save('miniLM_model_embeddings.npy', train_embeddings)\n",
    "# Save concatenated embeddings for all-mpnet-base-v2\n",
    "# np.save('mpnet_model_embeddings.npy', train_embeddings_mpnet)\n",
    "print('Both sets of text embeddings saved successfully')\n",
    "\n",
    "# For future runs\n",
    "minilm_embeds = np.load('miniLM_model_embeddings.npy')\n",
    "mpnet_embeds = np.load('mpnet_model_embeddings.npy')\n",
    "\n",
    "# Concatenate them\n",
    "final_text_features = np.concatenate([minilm_embeds, mpnet_embeds], axis=1)\n",
    "# Save the concatenated embeddings\n",
    "np.save('ensemble_embeddings.npy', final_text_features)\n",
    "\n",
    "print(f\"Concatenated Text Feature Shape: {final_text_features.shape}\")\n",
    "print(f\"Total dimensionality of the text feature: {final_text_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45c04af-7b58-4a90-9465-786232d918f2",
   "metadata": {},
   "source": [
    "## Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "701204df-8202-4127-bb17-0a16cd571d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threaded download of 72288 unique images with 64 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62058/72288 [00:02<00:00, 25197.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to download - https://m.media-amazon.com/images/I/51mjZYDYjyL.jpg (Error: HTTPError)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72288/72288 [00:03<00:00, 23295.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image download complete.\n",
      "Verified images on disk: 74999 / 75000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "# --- Image Download Function ---\n",
    "def download_image_refined(image_link, savefolder):\n",
    "    if not isinstance(image_link, str) or not image_link.startswith('http'):\n",
    "        return\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(savefolder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # BEST PRACTICE: Use requests with timeout and stream=True for large files\n",
    "        response = requests.get(image_link, stream=True)\n",
    "        response.raise_for_status()  # Check for bad status code (4xx or 5xx)\n",
    "\n",
    "        with open(image_save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                \n",
    "    except Exception as ex:\n",
    "        # Logging errors for debugging is cleaner\n",
    "        print(f'Warning: Failed to download - {image_link} (Error: {ex.__class__.__name__})')\n",
    "        # Clean up the potentially corrupted file fragment if download failed\n",
    "        if os.path.exists(image_save_path):\n",
    "            os.remove(image_save_path)\n",
    "            \n",
    "    return\n",
    "\n",
    "# --- Threaded Download Wrapper  ---\n",
    "def download_images_threaded(image_links, download_folder, max_workers=64): # Increased workers for faster I/O\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    # Use a set to only download unique links, saving time and disk space\n",
    "    unique_links = image_links.dropna().unique()\n",
    "\n",
    "    print(f\"Starting threaded download of {len(unique_links)} unique images with {max_workers} workers...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Use the refined function\n",
    "        list(tqdm(executor.map(partial(download_image_refined, savefolder=download_folder), unique_links), total=len(unique_links)))\n",
    "        \n",
    "    print(\"Image download complete.\")\n",
    "\n",
    "# --- Execution ---\n",
    "IMAGE_DIR = 'product_images'\n",
    "download_images_threaded(train_df['image_link'], IMAGE_DIR)\n",
    "\n",
    "# --- Map Local Paths Back to DataFrame ---\n",
    "def get_local_path(image_link, savefolder=IMAGE_DIR):\n",
    "    if pd.isna(image_link): return None\n",
    "    filename = Path(image_link).name\n",
    "    path = os.path.join(savefolder, filename)\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "train_df['image_path'] = train_df['image_link'].apply(get_local_path)\n",
    "successful_downloads = train_df['image_path'].notna().sum()\n",
    "print(f\"Verified images on disk: {successful_downloads} / {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28487508-d0dc-4043-af6b-842f275c9055",
   "metadata": {},
   "source": [
    "## Feature Extraction using ResNet50 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80beb248-1b13-490a-b836-0eee47b92ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for feature extraction: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for feature extraction: {device}\")\n",
    "\n",
    "# 1. Load Pre-trained Model (ResNet50)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# 2. Extract features by cutting off the final classification layer (Global Average Pooling is the last layer we keep)\n",
    "# The features vector size will be 2048\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model.eval() # Set model to evaluation mode\n",
    "model.to(device)\n",
    "\n",
    "# 3. Define Image Preprocessing Pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae408051-1422-42bc-867a-147db91d5bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting image feature extraction (Transfer Learning)...\n",
      "Image features saved to 'train_image_features.npy'.\n"
     ]
    }
   ],
   "source": [
    "def extract_resnet_features(image_path, model, preprocess, device):\n",
    "    \"\"\"Loads, preprocesses, and extracts features for a single image.\"\"\"\n",
    "    if image_path is None: return None\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(image)\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = model(img_tensor)\n",
    "        \n",
    "        # Squeeze the feature tensor (e.g., 1x2048x1x1 -> 2048) and convert to NumPy\n",
    "        return features.squeeze().cpu().numpy()\n",
    "\n",
    "    except Exception as e:\n",
    "        # If the file exists but is corrupted/unreadable\n",
    "        return None\n",
    "\n",
    "print(\"\\nStarting image feature extraction (Transfer Learning)...\")\n",
    "\n",
    "# This portion is commented out to prevent re-execution\n",
    "'''\n",
    "# Extract features and handle missing data\n",
    "image_features_list = []\n",
    "for path in tqdm(train_df['image_path'], total=len(train_df)):\n",
    "    features = extract_resnet_features(path, model, preprocess, device)\n",
    "    image_features_list.append(features)\n",
    "\n",
    "# Determine the dimension (2048 for ResNet50)\n",
    "# Find the first valid feature to get the shape\n",
    "valid_features = [f for f in image_features_list if f is not None]\n",
    "\n",
    "if not valid_features:\n",
    "    raise Exception(\"Image extraction failed for all samples. Check downloads.\")\n",
    "    \n",
    "feature_dim = valid_features[0].shape[0]\n",
    "\n",
    "# Create the final feature matrix with imputation and the missingness indicator (Best Practice)\n",
    "final_image_features = np.zeros((len(train_df), feature_dim), dtype=np.float32)\n",
    "train_df['image_missing'] = 0 \n",
    "imputation_count = 0\n",
    "\n",
    "for i, features in enumerate(image_features_list):\n",
    "    if features is not None:\n",
    "        final_image_features[i] = features\n",
    "    else:\n",
    "        # 1. Impute with zeros\n",
    "        final_image_features[i] = np.zeros(feature_dim)\n",
    "        # 2. Set the missingness indicator flag (Highly predictive feature!)\n",
    "        train_df.loc[i, 'image_missing'] = 1\n",
    "        imputation_count += 1\n",
    "        \n",
    "print(f\"Image feature extraction complete. Missing features imputed: {imputation_count}\")\n",
    "print(f\"Final Image Feature Shape: {final_image_features.shape}\")\n",
    "\n",
    "# Save the final image features (BEST PRACTICE)\n",
    "np.save('train_image_features.npy', final_image_features)\n",
    "'''\n",
    "print(\"Image features saved to 'train_image_features.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29b29b1e-c35c-40dd-84c4-db0e36ef118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features saved to 'train_image_features.npy'.\n"
     ]
    }
   ],
   "source": [
    "# After the image feature extraction has finished running\n",
    "#np.save('train_image_features.npy', final_image_features)\n",
    "print(\"Image features saved to 'train_image_features.npy'.\")\n",
    "\n",
    "# Later load them using:\n",
    "image_features = np.load('train_image_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bc99444-3997-43c6-a20b-506a71604839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features transformed and scaled using QuantileTransformer.\n",
      "    log_ipq  log_base_value\n",
      "0  0.726606        0.910873\n",
      "1  0.548158        0.421111\n",
      "2  0.726606       -0.337500\n",
      "3 -5.199338       -0.339521\n",
      "4  1.130517       -0.270485\n"
     ]
    }
   ],
   "source": [
    "# Apply Log transformation to handle skewness\n",
    "train_df['log_ipq'] = np.log1p(train_df['item_pack_quantity'])\n",
    "train_df['log_base_value'] = np.log1p(train_df['base_value'])\n",
    "\n",
    "# Select the final numerical features for scaling\n",
    "numerical_cols = ['log_ipq', 'log_base_value']\n",
    "\n",
    "# Initialize the QuantileTransformer\n",
    "# output_distribution='normal' is a common and powerful choice\n",
    "# n_quantiles=1000 ensures high precision (use max rows if less than 1000)\n",
    "qt_scaler = QuantileTransformer(output_distribution='normal', n_quantiles=1000, random_state=42)\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_df[numerical_cols] = qt_scaler.fit_transform(train_df[numerical_cols])\n",
    "import joblib\n",
    "\n",
    "# Save the fitted QuantileTransformer object for use on the test set\n",
    "joblib.dump(qt_scaler, 'qt_scaler.pkl')\n",
    "\n",
    "print(\"Numerical features transformed and scaled using QuantileTransformer.\")\n",
    "print(train_df[numerical_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa83236-cd38-4ccf-987b-b5b84945f5f9",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52555913-008e-43d6-abf1-50188039ebd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Unit binned feature successfully One-Hot Encoded.\n",
      "   unit_Count  unit_None  unit_Other  unit_Ounce/FlOz  unit_Pound\n",
      "0       False      False       False             True       False\n",
      "1       False      False       False             True       False\n",
      "2       False      False       False             True       False\n",
      "3       False      False       False             True       False\n",
      "4        True      False       False            False       False\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encode the binned base unit column\n",
    "base_unit_ohe = pd.get_dummies(train_df['base_unit_binned'], prefix='unit')\n",
    "\n",
    "print(\"Base Unit binned feature successfully One-Hot Encoded.\")\n",
    "print(base_unit_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "788df43f-2e23-4ecd-90fe-004bfd805f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item Name has been Target Encoded.\n",
      "                                                                                                                                                   item_name  \\\n",
      "0                                                                                                    La Victoria Green Taco Sauce Mild, 12 Ounce (Pack of 6)   \n",
      "1                                                                                          Salerno Cookies, The Original Butter Cookies, 8 Ounce (Pack of 4)   \n",
      "2                                                                               Bear Creek Hearty Soup Bowl, Creamy Chicken with Rice, 1.9 Ounce (Pack of 6)   \n",
      "3  Judeeâ€™s Blue Cheese Powder 11.25 oz - Gluten-Free and Nut-Free - Use in Seasonings and Salad Dressings - Great for Dips, Spreads and Sauces - Made in USA   \n",
      "4                                                                                                       kedem Sherry Cooking Wine, 12.7 Ounce - 12 per case.   \n",
      "\n",
      "   item_name_encoded  \n",
      "0           1.773256  \n",
      "1           2.647592  \n",
      "2           1.088562  \n",
      "3           3.444895  \n",
      "4           4.211979  \n"
     ]
    }
   ],
   "source": [
    "# Target Encoding for 'item_name'\n",
    "# This uses full-data mean (risks leakage).\n",
    "\n",
    "name_to_target_map = train_df.groupby('item_name')['log_price'].mean()\n",
    "train_df['item_name_encoded'] = train_df['item_name'].map(name_to_target_map)\n",
    "\n",
    "# Fill any new/missing item names with the overall mean\n",
    "train_df['item_name_encoded'] = train_df['item_name_encoded'].fillna(train_df['log_price'].mean())\n",
    "\n",
    "print(\"\\nItem Name has been Target Encoded.\")\n",
    "print(train_df[['item_name', 'item_name_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3eff10b7-f343-4632-9c75-0e8f7241e6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'name_to_target_map.pkl' successfully saved to disk.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Save the target encoding map from memory to disk\n",
    "joblib.dump(name_to_target_map, 'name_to_target_map.pkl')\n",
    "print(\"'name_to_target_map.pkl' successfully saved to disk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eac340-e66d-4d52-a0a3-776025df59fd",
   "metadata": {},
   "source": [
    "# Model Fusion and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4a03c0e-2be5-42a6-8c6a-1f3214c95676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'image_missing' column re-created on train_df.\n",
      "Re-calculated missing features imputed: 1\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH_COL = 'image_path' # <--- Verify this column name!\n",
    "\n",
    "# --- Re-create the 'image_missing' flag ---\n",
    "# This replicates the logic: a missing path leads to a missing feature (1)\n",
    "# and a present path leads to a present feature (0).\n",
    "# We assume that the only way features were 'None' was if the image_path was Null/Invalid.\n",
    "\n",
    "# Check for Nulls/NaNs in the image path column and convert to integer (0 or 1)\n",
    "# 1 = Missing, 0 = Present\n",
    "train_df['image_missing'] = train_df[IMAGE_PATH_COL].isnull().astype(int)\n",
    "\n",
    "# Optional: Verify the count matches your previous output\n",
    "imputation_count = train_df['image_missing'].sum()\n",
    "print(f\"'image_missing' column re-created on train_df.\")\n",
    "print(f\"Re-calculated missing features imputed: {imputation_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "214f3a1b-d1db-46e8-87d9-f65d4afabff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated and saved mean log price for test set imputation: 2.7392\n",
      "âœ… Feature components loaded and prepared.\n",
      "Total features calculated: 3208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold # Required for the next step\n",
    "\n",
    "# --- 1. Load High-Dimensional Features from Disk (Mmap Mode) ---\n",
    "# Keep mmap_mode='r' to prevent RAM loading\n",
    "train_text_features = np.load('ensemble_embeddings.npy', mmap_mode='r') \n",
    "train_image_features = np.load('train_image_features.npy', mmap_mode='r') \n",
    "\n",
    "# --- 2. Extract and Combine Simple Features (No Target Encoding Leakage) ---\n",
    "\n",
    "# CRITICAL: We remove 'item_name_encoded' to fix the leakage.\n",
    "simple_features = train_df[[\n",
    "    'log_ipq', \n",
    "    'log_base_value', \n",
    "    'image_missing' \n",
    "]] \n",
    "\n",
    "# Combine the One-Hot Encoded units with the simple features\n",
    "# base_unit_ohe is defined (assuming it's a DataFrame)\n",
    "X_simple_no_te = pd.concat([simple_features, base_unit_ohe], axis=1).values \n",
    "\n",
    "# 3. Cast the Simple Features and Target to the final required type\n",
    "# This is the only array creation we do outside the loop.\n",
    "X_simple_base = X_simple_no_te.astype(np.float32)\n",
    "y_train = train_df['log_price'].values.astype(np.float32)\n",
    "\n",
    "# --- 4. PREPARE ALL COMPONENTS FOR FOLDING ---\n",
    "# We use a list to hold the components. Concatenation happens only on the smaller fold slices.\n",
    "# The component order defines the final feature order.\n",
    "X_components = [\n",
    "    X_simple_base,            # Simple features + OHE (NumPy array)\n",
    "    train_text_features,      # Mmap-mapped NumPy array\n",
    "    train_image_features      # Mmap-mapped NumPy array\n",
    "]\n",
    "\n",
    "# --- CRITICAL FIX: Calculate and Save Mean Log Price ---\n",
    "train_log_price_mean = train_df['log_price'].mean()\n",
    "joblib.dump(train_log_price_mean, 'train_log_price_mean.pkl') \n",
    "print(f\"Calculated and saved mean log price for test set imputation: {train_log_price_mean:.4f}\")\n",
    "\n",
    "# Calculate the total features without running np.concatenate\n",
    "total_features = sum(c.shape[1] for c in X_components)\n",
    "\n",
    "print(f\"âœ… Feature components loaded and prepared.\")\n",
    "print(f\"Total features calculated: {total_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "360b49ab-ee4c-43dd-9481-4892f358516b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Memory-Safe 5-Fold Ensemble Training  ---\n",
      "\n",
      "Training Fold 1...\n",
      "Fold 1 SMAPE (FINAL FIXED): 53.3451%\n",
      "\n",
      "Training Fold 2...\n",
      "Fold 2 SMAPE (FINAL FIXED): 52.2639%\n",
      "\n",
      "Training Fold 3...\n",
      "Fold 3 SMAPE (FINAL FIXED): 52.4590%\n",
      "\n",
      "Training Fold 4...\n",
      "Fold 4 SMAPE (FINAL FIXED): 51.6617%\n",
      "\n",
      "Training Fold 5...\n",
      "Fold 5 SMAPE (FINAL FIXED): 52.4803%\n",
      "\n",
      "âœ… FINAL FIXED OOF SMAPE: 52.4420%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "# Assume X_components, y_train, raw_names, train_log_price_mean are correctly defined.\n",
    "# Assume lgb_smape is correctly defined.\n",
    "\n",
    "def lgb_smape(y_pred, train_data): # Note the parameter names are standard for LightGBM\n",
    "    \"\"\"\n",
    "    Custom evaluation metric for LightGBM that calculates SMAPE.\n",
    "    NOTE: LightGBM passes the Dataset object (train_data) for true labels.\n",
    "    \"\"\"\n",
    "    # CRITICAL FIX: Extract true labels from the Dataset object\n",
    "    y_true = train_data.get_label()\n",
    "    \n",
    "    # Inverse transform to actual price scale (Price = exp(log_price) - 1)\n",
    "    y_true_price = np.expm1(y_true)\n",
    "    y_pred_price = np.expm1(y_pred)\n",
    "    \n",
    "    # Add a small epsilon for numerical stability\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    # Calculate SMAPE\n",
    "    numerator = np.abs(y_pred_price - y_true_price)\n",
    "    denominator = (np.abs(y_true_price) + np.abs(y_pred_price)) / 2 + epsilon\n",
    "    smape_value = np.mean(numerator / denominator) * 100\n",
    "    \n",
    "    # Return (eval_name, result, is_higher_better) - standard LightGBM format\n",
    "    return 'SMAPE', smape_value, False\n",
    "\n",
    "# Reduce n_estimators as a safety measure for the deadline\n",
    "lgb_params = {\n",
    "    'objective': 'regression_l1', 'n_estimators': 2000, 'learning_rate': 0.02, \n",
    "    'num_leaves': 100, 'lambda_l1': 0.5, 'lambda_l2': 0.5, 'verbose': -1, 'n_jobs': -1, 'seed': 42\n",
    "}\n",
    "\n",
    "final_models = []\n",
    "smape_scores = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) \n",
    "\n",
    "print(\"\\n--- Starting Memory-Safe 5-Fold Ensemble Training  ---\")\n",
    "\n",
    "\n",
    "# --- 2. Optimized Training Loop ---\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_components[0], y_train)):\n",
    "    \n",
    "    print(f\"\\nTraining Fold {fold+1}...\")\n",
    "\n",
    "    # A. Dynamic Slicing and Target Encoding\n",
    "    train_parts = [c[train_index] for c in X_components]\n",
    "    val_parts = [c[val_index] for c in X_components]\n",
    "\n",
    "    # Target Encoding Fix\n",
    "    train_names_fold = train_df['item_name'].iloc[train_index]\n",
    "    val_names_fold = train_df['item_name'].iloc[val_index]\n",
    "    te_map = pd.Series(y_train[train_index], index=train_names_fold.index).groupby(train_names_fold).mean()\n",
    "    val_te_feature = val_names_fold.map(te_map).fillna(train_log_price_mean).values.astype(np.float32).reshape(-1, 1)\n",
    "    train_te_placeholder = np.zeros((len(train_index), 1), dtype=np.float32)\n",
    "\n",
    "    # B. ASSEMBLE FINAL ARRAYS (USE CONCATENATE ON SLICED DATA)\n",
    "    X_train_fold = np.concatenate(train_parts + [train_te_placeholder], axis=1)\n",
    "    X_val_fold = np.concatenate(val_parts + [val_te_feature], axis=1)\n",
    "    y_train_fold = y_train[train_index]\n",
    "    y_val_fold = y_train[val_index]\n",
    "\n",
    "    # --- C. LightGBM Dataset Creation (Using single array) ---\n",
    "    lgb_train = lgb.Dataset(\n",
    "        data=X_train_fold, \n",
    "        label=y_train_fold,\n",
    "    )\n",
    "    lgb_val = lgb.Dataset(\n",
    "        data=X_val_fold, \n",
    "        label=y_val_fold,\n",
    "        reference=lgb_train\n",
    "    )\n",
    "\n",
    "    # --- D. TRAIN MODEL (Corrected for all version TypeErrors) ---\n",
    "    model_lgb = lgb.train(\n",
    "        # Pass the standard L1 metric in params \n",
    "        params={**lgb_params, 'verbose': -1, 'metric': 'l1'}, \n",
    "        train_set=lgb_train,\n",
    "        valid_sets=[lgb_val],\n",
    "        valid_names=['validation'],\n",
    "        num_boost_round=lgb_params['n_estimators'],\n",
    "        \n",
    "        # Pass your custom SMAPE function via the 'feval' argument\n",
    "        feval=lgb_smape, \n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    final_models.append(model_lgb)\n",
    "    \n",
    "    # Predict and clean up\n",
    "    # NOTE: Predict on the single concatenated array\n",
    "    val_preds = model_lgb.predict(X_val_fold, num_iteration=model_lgb.best_iteration)\n",
    "    \n",
    "    # --- CRITICAL FIX: Inline SMAPE Calculation for NumPy Arrays ---\n",
    "    # 1. Inverse transform to actual price scale (y_true and y_pred are NumPy arrays here)\n",
    "    y_true_price = np.expm1(y_val_fold)\n",
    "    y_pred_price = np.expm1(val_preds)\n",
    "    \n",
    "    # 2. Calculate SMAPE directly\n",
    "    epsilon = 1e-6\n",
    "    numerator = np.abs(y_pred_price - y_true_price)\n",
    "    denominator = (np.abs(y_true_price) + np.abs(y_pred_price)) / 2 + epsilon\n",
    "    smape = np.mean(numerator / denominator) * 100\n",
    "    \n",
    "    smape_scores.append(smape)\n",
    "    print(f\"Fold {fold+1} SMAPE (FINAL FIXED): {smape:.4f}%\")\n",
    "    \n",
    "    # Explicit garbage collection to aid memory\n",
    "    del lgb_train, lgb_val, X_train_fold, X_val_fold, y_train_fold, y_val_fold \n",
    "    gc.collect()\n",
    "\n",
    "final_smape = np.mean(smape_scores)\n",
    "print(f\"\\nâœ… FINAL FIXED OOF SMAPE: {final_smape:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e865290-37ac-4c4b-a992-4111ee2ff16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved 3 ensemble models to the 'final_ensemble_models' folder.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a folder to store the models\n",
    "model_dir = 'final_ensemble_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save each of the 3 trained models\n",
    "for i, model in enumerate(final_models):\n",
    "    joblib.dump(model, os.path.join(model_dir, f'lgbm_fold_{i+1}.pkl'))\n",
    "\n",
    "print(f\"\\nSuccessfully saved 3 ensemble models to the '{model_dir}' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aad4f8-4537-434a-b82a-5f0caedca726",
   "metadata": {},
   "source": [
    "## Repeating the feature engineering steps for the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f45a0a57-8c3e-4438-b25f-55c569d71544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id  \\\n",
      "0     100179   \n",
      "1     245611   \n",
      "2     146263   \n",
      "3      95658   \n",
      "4      36806   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      catalog_content  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Item Name: Rani 14-Spice Eshamaya's Mango Chutney (Indian Preserve) 10.5oz (300g) Glass Jar, Ready to eat, Vegan ~ Gluten Free, All Natural, NON-GMO\\nBullet Point 1: You'll LOVE our 14-Spice Eshamaya's Mango Chutney Chutney by Rani Brand--Here's Why:\\nBullet Point 2: ðŸ¥­All Natural, Non-GMO, No Preservatives, Gluten Free PREMIUM Gourmet Food Grade Chutney.\\nBullet Point 3: ðŸ¥­Authentic Family Rani Recipe. Rani is a USA based company selling Indian Foods for over 40 years, buy with confidence!\\nBullet Point 4: ðŸ¥­Great Spicy Taste, Awesome with Wine & Cheese! Packaged in a re-closeable glass jar\\nBullet Point 5: ðŸ¥­Net Wt. 10.5oz - Authentic Product of India\\nProduct Description: Mango chutney is made from diced green mangoes cooked with sugar. Spices are added to distinguish the different types of chutneys. Hot mango chutney is spiced with chilli powder which give the chutney heat and a deep amber color. Sweet Mango chutney allows the pallet to appreciate the flavor of the mango, adding a hint of vinegar for sourness, while major grey chutney mixes raisins, ginger powder, chilli powder and an array of spices to give complexity to the chutney. Try Rani Chutney's with pizza, salads, burgers, sandwiches, cheeses and anything else you can imagine!\\nValue: 10.5\\nUnit: Ounce\\n   \n",
      "1  Item Name: Natural MILK TEA Flavoring extract by HALO PANTRY (2oz bottle) | Perfect for customizing ANY baking, candy, dessert or drink recipes | Dairy Free, Dye-Free, Gluten Free, Zero Sugars, Zero Calories, Gourmet (Pack of 1)\\nBullet Point 1: Authentic Tasting, Asian-Inspired Natural flavorings made exclusively for use in any baking, cooking, dessert, candy, or drink recipes.\\nBullet Point 2: NATURAL : Gluten-Free, Dairy-Free, Zero Sugars, Zero Calories, Soy-Free, Sodium Free, GMO-Free, PG-Free, Oil-Free\\nBullet Point 3: No Colors, No Sweeteners, No Artificial Ingredients, No Preservatives\\nBullet Point 4: All ingredients & packaging sourced and made within the USA\\nBullet Point 5: Tastes like Brown Sugar bubble milk teas\\nBullet Point 6: new 2oz Professional Series bottle for frequent bakers and cooks.\\nProduct Description: Check our popular Milk Tea flavoring extract in a New larger bottle for use in any food or drink recipes. Perfect substitute for your average vanilla extract if you want to amplify the taste of your recipes. *HALO PANTRY is a premium line of Asian-inspired flavorings made exclusively for use in any baked goods, cooking, dessert, candy, or drink recipes. Our product line is very aromatic & flavorful to help enhance your recipes. The mission of HALO PANTRY brand is to make the DIY, at-home cooking/baking experience simple, fun, and to also encourage others to explore asian-inspired flavors. *Unlike other food flavoring products, Halo Pantry only adds flavors & does not alter or negatively impact the taste of your original recipe because it doesn't contain any sweeteners or other additives. With our product, you have complete control of your own recipes.\\nValue: 2.0\\nUnit: Fl Oz\\n   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Item Name: Honey Filled Hard Candy - Bulk Pack 2 Pounds - Individually Wrapped\\nBullet Point 1: Honey Filled Hard Candy; 2-pound bulk pack; approximately 180 pieces per order\\nBullet Point 2: Treat yourself to the soothing sweetness of candy that captures the essence of natural honey\\nBullet Point 3: Each piece is expertly crafted with a hard candy shell that gives way to a luscious, liquid honey center\\nBullet Point 4: Suitable for soothing a sore throat, sweetening a cup of tea, or simply enjoying as a sweet snack\\nBullet Point 5: Whether at home, in the office, or on the move, this candy will satisfy your sweet tooth and offer a moment of indulgence\\nProduct Description: Honey Filled Hard Candy - Bulk Pack 2 Pounds - Individually Wrapped\\nValue: 32.0\\nUnit: Ounce\\n   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Item Name: Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)\\nValue: 2.0\\nUnit: Count\\n   \n",
      "4                                                                                                                                                                                                                                         Item Name: McCormick Culinary Vanilla Extract, 32 fl oz - One 32 Fluid Ounce Container of Gluten Free and Non-GMO Pure Vanilla Extract Made From Premium Vanilla Beans Perfect for Chefs & Home Bakers\\nBullet Point 1: PREMIUM INGREDIENTS: McCormick Culinary Pure Vanilla Extract delivers delightfully satisfying flavor and features a dark brown color; created especially for chefs, this vanilla extract is highly fragrant with unrivaled performance in a ready-to-use format\\nBullet Point 2: RICH VANILLA FLAVOR: With its caramelized, rich, bourbon-rummy flavor notes, McCormick Culinary vanilla extract helps complement and intensify other flavors in inventive recipes\\nBullet Point 3: EASE OF USE: Our 32-ounce size is perfect for dispensing individual drops of vanilla extract, and you can easily unscrew the convenient flip top to add larger amounts to any large recipe; you can buy these 32-ounce bottles individually or in bulk\\nBullet Point 4: MENU VERSATILITY: McCormick Culinary Pure Vanilla Extract gives sweet, rich flavor to a wide variety of dishes and desserts; this pure vanilla extract tastes great in any beverage or sweet baked good and helps draw the acidity out of foods like lemons\\nBullet Point 5: NATURAL INGREDIENTS: McCormick Culinary Pure Vanilla Extract is kosher and non-GMO, so you can feel comfortable using it in all of your favorite recipes; this vanilla extract contains no added sugar for a pure and balanced flavor your customers will love\\nValue: 32.0\\nUnit: Fl Oz\\n   \n",
      "\n",
      "                                            image_link  \n",
      "0  https://m.media-amazon.com/images/I/71hoAn78AWL.jpg  \n",
      "1  https://m.media-amazon.com/images/I/61ex8NHCIjL.jpg  \n",
      "2  https://m.media-amazon.com/images/I/61KCM61J8eL.jpg  \n",
      "3  https://m.media-amazon.com/images/I/51Ex6uOH7yL.jpg  \n",
      "4  https://m.media-amazon.com/images/I/71QYlrOMoSL.jpg  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d148c-e263-4193-9e56-07e28fc99197",
   "metadata": {},
   "source": [
    "# Test Set Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11fe5691-d4a7-4721-8773-613c952fa212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Test Data Feature Transformation ---\n",
      "All required non-embedding feature steps completed on test_df.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  FEATURE PARSING FUNCTIONS\n",
    "\n",
    "\n",
    "# 1. Catalog Content Cleaning (Handles Emojis/Non-ASCII for robust parsing)\n",
    "def clean_catalog_content(text):\n",
    "    \"\"\"Removes emojis/non-ASCII chars and cleans up whitespace.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    # Remove Emojis and non-ASCII characters\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Clean up common delimiters/whitespace\n",
    "    text = re.sub(r'[\\n\\r]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# 2. Extract Item Name (Must use cleaned content for robustness)\n",
    "def extract_item_name(text):\n",
    "    \"\"\"Extracts the Item Name from cleaned content.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = str(text)\n",
    "    match = re.search(r'Item Name: (.*)', text, re.IGNORECASE | re.DOTALL)\n",
    "    if match:\n",
    "        full_string = match.group(1)\n",
    "        item_name = full_string.split('\\n')[0].strip()\n",
    "        return item_name.rstrip(',')\n",
    "    return None\n",
    "\n",
    "# 3. Extract Base Value\n",
    "def extract_base_value(text):\n",
    "    \"\"\"Extracts the numerical 'Value' field from cleaned content.\"\"\"\n",
    "    match = re.search(r'Value: ([\\d.]+)', str(text))\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# 4. Extract Base Unit\n",
    "def extract_base_unit(text):\n",
    "    \"\"\"Extracts the categorical 'Unit' field from cleaned content.\"\"\"\n",
    "    match = re.search(r'Unit: (\\w+)', str(text))\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return 'Unknown'\n",
    "\n",
    "# 5. Extract Item Pack Quantity (IPQ)\n",
    "IPQ_PATTERN = r'(\\d+)\\s*(?:per\\s*case|per\\s*pack)|(?:pack of|per\\s*case)\\s*(\\d+)|(\\d+)\\s*\\b(?:pack|count|pcs|ct|case|box)\\b'\n",
    "def extract_ipq(text):\n",
    "    \"\"\"Extracts the number of items/quantity, defaulting to 1.\"\"\"\n",
    "    if pd.isna(text): return 1\n",
    "    text = str(text).lower()\n",
    "    matches = re.findall(IPQ_PATTERN, text)\n",
    "    max_ipq = 1\n",
    "    for m in matches:\n",
    "        for num_str in m:\n",
    "            if num_str:\n",
    "                try:\n",
    "                    num = int(num_str)\n",
    "                    if num > max_ipq:\n",
    "                        max_ipq = num\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return max_ipq\n",
    "\n",
    "# 6. Robust Unit Normalization\n",
    "def normalize_unit(unit):\n",
    "    if pd.isna(unit): return 'Unknown'\n",
    "    unit = unit.lower().strip()\n",
    "    if unit in ['oz', 'ounce', 'fl oz', 'fl', 'fluid']: return 'Ounce/FlOz'\n",
    "    if unit in ['lb', 'pound', 'pounds', 'lbs']: return 'Pound'\n",
    "    if unit in ['g', 'gram', 'grams']: return 'Gram'\n",
    "    if unit in ['l', 'liter', 'quart']: return 'Liter'\n",
    "    if unit in ['ml', 'millilitre', 'milliliter']: return 'Milliliter'\n",
    "    if unit in ['count', 'ct', 'pcs', 'ea', 'pac', 'packet', 'pk', 'pack']: return 'Count'\n",
    "    if unit == 'none': return 'None'\n",
    "    return unit\n",
    "\n",
    "# 7. Deep Text Cleaning for Transformer Input\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans text for Transformer input by normalizing and removing noise.\"\"\"\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^a-z0-9\\s.,?!:;\\'\"()_]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "#   EXECUTION ON TEST DATA\n",
    "\n",
    "print(\"\\n--- Starting Test Data Feature Transformation ---\")\n",
    "\n",
    "# A. Initial Cleaning\n",
    "test_df['catalog_content_cleaned'] = test_df['catalog_content'].apply(clean_catalog_content)\n",
    "\n",
    "# B. Feature Extraction and Normalization (Using CLEANED content)\n",
    "test_df['item_name'] = test_df['catalog_content_cleaned'].apply(extract_item_name)\n",
    "test_df['base_value'] = test_df['catalog_content_cleaned'].apply(extract_base_value)\n",
    "test_df['item_pack_quantity'] = test_df['catalog_content_cleaned'].apply(extract_ipq)\n",
    "test_df['base_unit'] = test_df['catalog_content_cleaned'].apply(extract_base_unit)\n",
    "test_df['base_unit'] = test_df['base_unit'].apply(normalize_unit)\n",
    "\n",
    "# C. Unit Binning (CRITICAL: Uses Training Artifact)\n",
    "test_df['base_unit_binned'] = test_df['base_unit'].apply(\n",
    "    # Uses the set derived from the CORRECTED TRAINING data binning\n",
    "    lambda x: 'Other' if x in low_frequency_units else x\n",
    ")\n",
    "# One-Hot Encoding for this column must be performed later, ensuring columns align with the training set.\n",
    "\n",
    "\n",
    "# D. Target Encoding (CRITICAL: Uses Training Artifact)\n",
    "# The full target encoding map should be calculated using the entire y_train\n",
    "# This map is safe for the test set.\n",
    "\n",
    "# Assuming train_df_raw is the original, full training DataFrame\n",
    "# Assuming y_train is the final, full target array (log_price)\n",
    "\n",
    "# 1. Calculate the full, safe map using the entire training set\n",
    "# NOTE: We assume 'raw_names' from the training setup is still available, or we use train_df_raw['item_name']\n",
    "raw_names_train = train_df['item_name'] \n",
    "full_te_map = raw_names_train.map(pd.Series(y_train, index=raw_names_train.index)).groupby(raw_names_train).mean()\n",
    "\n",
    "# 2. Apply the map to the test set\n",
    "test_df['item_name_encoded'] = test_df['item_name'].map(full_te_map)\n",
    "\n",
    "# 3. Fill new/missing items with the overall mean log_price from the TRAINING data\n",
    "# (train_log_price_mean was saved earlier)\n",
    "test_df['item_name_encoded'] = test_df['item_name_encoded'].fillna(train_log_price_mean)\n",
    "\n",
    "\n",
    "# E. Numerical Scaling (CRITICAL: Uses Training Artifact)\n",
    "# Log transformation\n",
    "test_df['log_ipq'] = np.log1p(test_df['item_pack_quantity'].fillna(0)) \n",
    "test_df['log_base_value'] = np.log1p(test_df['base_value'].fillna(0)) \n",
    "\n",
    "# Final scaling using the fitted QuantileTransformer\n",
    "numerical_cols = ['log_ipq', 'log_base_value']\n",
    "qt_scaler = joblib.load('qt_scaler.pkl')\n",
    "test_df[numerical_cols] = qt_scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "\n",
    "# F. Text Input for Embeddings\n",
    "test_df['clean_catalog_content'] = test_df['catalog_content'].apply(clean_text)\n",
    "\n",
    "print(\"All required non-embedding feature steps completed on test_df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64428bd4-202a-432c-8331-1f05c3d49db5",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Text & Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79a515cc-9822-4359-8ea1-cf2168a035be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model: all-MiniLM-L6-v2...\n",
      "\n",
      "--- Generating Text Embeddings for TEST Set (NLP) ---\n",
      "Converting text data into high-dimensional numerical vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf0cb40bd064c57901dd24c0d0e8615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text embeddings generated successfully for the TEST set.\n",
      "Shape of test embeddings: (75000, 384)\n",
      "Text features saved to 'test_text_features.npy'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll use the 'all-MiniLM-L6-v2' model for efficiency and performance\n",
    "model_name = 'all-MiniLM-L6-v2' \n",
    "\n",
    "print(f\"Loading Sentence Transformer model: {model_name}...\")\n",
    "#  Load the model in memory (same as training)\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "#  Use the CLEANED text column from the TEST DataFrame\n",
    "text_data_test = test_df['clean_catalog_content'].tolist()\n",
    "\n",
    "print(\"\\n--- Generating Text Embeddings for TEST Set (NLP) ---\")\n",
    "print(\"Converting text data into high-dimensional numerical vectors...\")\n",
    "\n",
    "# Encode the text data. This is a resource-intensive step.\n",
    "test_text_features = model.encode(text_data_test, \n",
    "                                  show_progress_bar=True, \n",
    "                                  convert_to_numpy=True,\n",
    "                                  batch_size=32) # Use the same batch size\n",
    "\n",
    "embedding_dim = test_text_features.shape[1]\n",
    "\n",
    "print(f\"\\nText embeddings generated successfully for the TEST set.\")\n",
    "print(f\"Shape of test embeddings: {test_text_features.shape}\")\n",
    "\n",
    "# Save the test embeddings for later concatenation\n",
    "np.save('test_text_features.npy', test_text_features)\n",
    "print(\"Text features saved to 'test_text_features.npy'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "024f5c61-5379-4628-9d9f-893eb01c9e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model: all-mpnet-base-v2...\n",
      "\n",
      "--- Generating Second Text Embeddings for TEST Set (MPNet) ---\n",
      "Converting text data into high-dimensional numerical vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929cb1eea48e44d3ac317806daf5b554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MPNet embeddings generated successfully for the TEST set.\n",
      "Shape of MPNet test embeddings: (75000, 768)\n",
      "Each product's description is now represented by a 768-dimensional vector.\n",
      "MPNet features saved to 'test_mpnet_features.npy'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll use the 'all-mpnet-base-v2' model now for richer semantic understanding\n",
    "model_name = 'all-mpnet-base-v2' \n",
    "\n",
    "print(f\"Loading Sentence Transformer model: {model_name}...\")\n",
    "# CRITICAL: Load the model in memory (same as training)\n",
    "model_mpnet = SentenceTransformer(model_name)\n",
    "\n",
    "# CRITICAL: Use the CLEANED text column from the TEST DataFrame\n",
    "text_data_test = test_df['clean_catalog_content'].tolist()\n",
    "\n",
    "print(\"\\n--- Generating Second Text Embeddings for TEST Set (MPNet) ---\")\n",
    "print(\"Converting text data into high-dimensional numerical vectors...\")\n",
    "\n",
    "# Encode the text data. This is a resource-intensive step.\n",
    "test_embeddings_mpnet = model_mpnet.encode(text_data_test, \n",
    "                                           show_progress_bar=True, \n",
    "                                           convert_to_numpy=True,\n",
    "                                           batch_size=32) # Use the same batch size\n",
    "\n",
    "embedding_dim_mpnet = test_embeddings_mpnet.shape[1]\n",
    "\n",
    "print(f\"\\nMPNet embeddings generated successfully for the TEST set.\")\n",
    "print(f\"Shape of MPNet test embeddings: {test_embeddings_mpnet.shape}\")\n",
    "print(f\"Each product's description is now represented by a {embedding_dim_mpnet}-dimensional vector.\")\n",
    "\n",
    "# FINAL STEP: Save the MPNet test embeddings \n",
    "np.save('test_mpnet_features.npy', test_embeddings_mpnet)\n",
    "print(\"MPNet features saved to 'test_mpnet_features.npy'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e96bc9dd-8663-48c8-9241-c02e2434ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Test Text Feature Shape: (75000, 1152)\n",
      "Total dimensionality of the test text feature: 1152\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Load the individual test embeddings ---\n",
    "\n",
    "minilm_embeds_test = np.load('test_text_features.npy') \n",
    "mpnet_embeds_test = np.load('test_mpnet_features.npy') \n",
    "\n",
    "# --- Concatenate them horizontally (axis=1) ---\n",
    "final_text_features_test = np.concatenate([minilm_embeds_test, mpnet_embeds_test], axis=1)\n",
    "\n",
    "# --- Save the concatenated embeddings for the final X_test matrix creation ---\n",
    "np.save('ensemble_embeddings_test.npy', final_text_features_test)\n",
    "\n",
    "print(f\"Concatenated Test Text Feature Shape: {final_text_features_test.shape}\")\n",
    "print(f\"Total dimensionality of the test text feature: {final_text_features_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6770740b-3ada-4789-856f-65388d73107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threaded download of 72222 unique images with 64 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72222/72222 [00:02<00:00, 25380.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to download - https://m.media-amazon.com/images/I/813CjSgHj0S.jpg (Error: HTTPError)\n",
      "Image download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified images on disk for TEST set: 74999 / 75000\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "\n",
    "# --- Image Download Function  ---\n",
    "def download_image_refined(image_link, savefolder):\n",
    "    if not isinstance(image_link, str) or not image_link.startswith('http'):\n",
    "        return\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(savefolder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(image_link, stream=True) # Added a timeout for robustness\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(image_save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "                \n",
    "    except Exception as ex:\n",
    "        # Logging errors for debugging is cleaner\n",
    "        print(f'Warning: Failed to download - {image_link} (Error: {ex.__class__.__name__})')\n",
    "        if os.path.exists(image_save_path):\n",
    "            os.remove(image_save_path)\n",
    "            \n",
    "    return\n",
    "\n",
    "# --- Threaded Download Wrapper ---\n",
    "def download_images_threaded(image_links, download_folder, max_workers=64):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    # Use a set to only download unique links, saving time and disk space\n",
    "    unique_links = image_links.dropna().unique()\n",
    "\n",
    "    print(f\"Starting threaded download of {len(unique_links)} unique images with {max_workers} workers...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        list(tqdm(executor.map(partial(download_image_refined, savefolder=download_folder), unique_links), total=len(unique_links)))\n",
    "        \n",
    "    print(\"Image download complete.\")\n",
    "\n",
    "# --- Path Mapping Function ---\n",
    "def get_local_path(image_link, savefolder): # Modified to accept savefolder argument\n",
    "    if pd.isna(image_link): return None\n",
    "    filename = Path(image_link).name\n",
    "    path = os.path.join(savefolder, filename)\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "\n",
    "\n",
    "#   EXECUTION ON test_df\n",
    "\n",
    "IMAGE_DIR_TEST = 'product_images' # Reusing the directory name is often simplest\n",
    "\n",
    "# 1. Execute the threaded download on the test_df links\n",
    "download_images_threaded(test_df['image_link'], IMAGE_DIR_TEST)\n",
    "\n",
    "# 2. Map Local Paths Back to Test DataFrame\n",
    "test_df['image_path'] = test_df['image_link'].apply(partial(get_local_path, savefolder=IMAGE_DIR_TEST))\n",
    "\n",
    "# 3. Create the 'image_missing' flag (needed for X_test matrix)\n",
    "test_df['image_missing'] = test_df['image_path'].isna()\n",
    "\n",
    "successful_downloads = test_df['image_path'].notna().sum()\n",
    "print(f\"Verified images on disk for TEST set: {successful_downloads} / {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3027ba12-cfdd-40e8-ad8f-d7ab5199e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for feature extraction: cpu\n",
      "\n",
      "--- Generating Image Embeddings for TEST Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Test Features:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 35079/75000 [2:02:04<2:30:54,  4.41it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Extracting Test Features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75000/75000 [6:20:06<00:00,  3.29it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image embeddings generated successfully for the TEST set.\n",
      "Shape of test image features: (75000, 2048)\n",
      "Image features saved to 'test_image_features.npy'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- I. Model and Preprocessing Setup  ---\n",
    "\n",
    "print(\"Using device for feature extraction: cpu\")\n",
    "\n",
    "# 1. Load Pre-trained Model (ResNet50)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# 2. Extract features by cutting off the final classification layer\n",
    "# The features vector size will be 2048\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model.eval() # Set model to evaluation mode\n",
    "model.to(device)\n",
    "\n",
    "# 3. Define Image Preprocessing Pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- II. Feature Extraction Function ---\n",
    "\n",
    "def extract_image_features(image_path, model, preprocess, device):\n",
    "    \"\"\"Loads, preprocesses an image, and extracts features.\"\"\"\n",
    "    if image_path is None or not os.path.exists(image_path):\n",
    "        # Return a zero vector for missing images\n",
    "        return np.zeros(2048, dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(img_tensor).squeeze().cpu().numpy()\n",
    "        \n",
    "        # Features are a 2048-dimensional vector after squeeze and flatten\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return a zero vector if loading or processing fails\n",
    "        # print(f\"Error processing image {image_path}: {e}\")\n",
    "        return np.zeros(2048, dtype=np.float32)\n",
    "\n",
    "# --- III. Execution on test_df ---\n",
    "\n",
    "print(\"\\n--- Generating Image Embeddings for TEST Set ---\")\n",
    "\n",
    "# Use the 'image_path' column created in the test_df\n",
    "test_image_paths = test_df['image_path'].tolist()\n",
    "\n",
    "# Apply the feature extraction to all test images\n",
    "# Using a list comprehension is clean and efficient for feature extraction\n",
    "test_image_features_list = [\n",
    "    extract_image_features(path, model, preprocess, device) \n",
    "    for path in tqdm(test_image_paths, desc=\"Extracting Test Features\")\n",
    "]\n",
    "\n",
    "test_image_features = np.array(test_image_features_list)\n",
    "\n",
    "print(f\"\\nImage embeddings generated successfully for the TEST set.\")\n",
    "print(f\"Shape of test image features: {test_image_features.shape}\")\n",
    "\n",
    "# FINAL STEP: Save the image embeddings for later concatenation\n",
    "np.save('test_image_features.npy', test_image_features)\n",
    "print(\"Image features saved to 'test_image_features.npy'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2a851-f15b-4ef1-adcd-97b76698ea71",
   "metadata": {},
   "source": [
    "## Creates image_missing flag without downloading images again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48f3d035-f076-41f7-b2ff-b4a4c7d13187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified images on disk and paths mapped for TEST set: 74999 / 75000\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Assuming IMAGE_DIR_TEST is still defined from your previous setup\n",
    "IMAGE_DIR_TEST = 'product_images' # Ensure this matches your download directory\n",
    "\n",
    "# --- Path Mapping Function (Needed to run the partial) ---\n",
    "def get_local_path(image_link, savefolder):\n",
    "    if pd.isna(image_link): return None\n",
    "    filename = Path(image_link).name\n",
    "    path = os.path.join(savefolder, filename)\n",
    "    # CRITICAL: This checks if the file actually exists where it should be\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "# 1. Map Local Paths Back to Test DataFrame\n",
    "test_df['image_path'] = test_df['image_link'].apply(partial(get_local_path, savefolder=IMAGE_DIR_TEST))\n",
    "\n",
    "# 2. Create the 'image_missing' flag (needed for X_test matrix)\n",
    "# YES, you must keep this flag as it is a crucial feature in your simple feature matrix.\n",
    "test_df['image_missing'] = test_df['image_path'].isna()\n",
    "\n",
    "successful_downloads = test_df['image_path'].notna().sum()\n",
    "print(f\"Verified images on disk and paths mapped for TEST set: {successful_downloads} / {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5486d-52d0-4760-8162-4ee6c63b0950",
   "metadata": {},
   "source": [
    "## Final Feature Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9419827d-5ebb-486e-a1ea-9a5503927069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE features created and aligned with training set.\n",
      "Test OHE Shape: (75000, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_categories = train_df['base_unit_binned'].unique()\n",
    "\n",
    "\n",
    "# 1. Apply OHE to the test set\n",
    "test_base_unit_ohe = pd.get_dummies(\n",
    "    test_df['base_unit_binned'],\n",
    "    prefix='unit'\n",
    ")\n",
    "\n",
    "# 2. Reindex the test OHE features to match the exact categories from training\n",
    "test_base_unit_ohe = test_base_unit_ohe.reindex(\n",
    "    columns=[f'unit_{cat}' for cat in training_categories], \n",
    "    fill_value=False # Use False or 0, depending on how your model handles boolean features\n",
    ")\n",
    "# Note: Converting boolean to int (1/0) is safer for LightGBM if not handled automatically\n",
    "test_base_unit_ohe = test_base_unit_ohe.astype(int)\n",
    "\n",
    "print(\"OHE features created and aligned with training set.\")\n",
    "print(f\"Test OHE Shape: {test_base_unit_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1057cff3-0e91-46e1-ad65-dc668cedc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the ID column to a new variable\n",
    "test_sample_ids = test_df['sample_id'].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28baf8e-0b4f-404a-8c69-921f71d351d7",
   "metadata": {},
   "source": [
    "## Test Matrix Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e542b3d-1930-4dc5-a364-20580d40d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_simple_test_base Shape: (75000, 8)\n",
      "Total features (before TE) calculated: 3208\n",
      "Test components assembled for memory-safe prediction.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- Load Saved Feature Arrays (Ensure mmap_mode='r' for image features) ---\n",
    "final_text_features_test = np.load('ensemble_embeddings_test.npy', allow_pickle=False) \n",
    "# Note: Image features were likely dropped in the final training run. Re-include if you kept them.\n",
    "test_image_features = np.load('test_image_features.npy', mmap_mode='r') \n",
    "\n",
    "\n",
    "# 1. Create the Simple/Scalar Feature Matrix (Excluding Target Encoded Feature)\n",
    "# CRITICAL: We DO NOT include 'item_name_encoded' here.\n",
    "X_scalar_test = test_df[[\n",
    "    'log_ipq', \n",
    "    'log_base_value', \n",
    "    'image_missing' \n",
    "]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2. Combine Scalar and OHE Features into the Base Test Matrix\n",
    "X_simple_test_base = pd.concat([\n",
    "    X_scalar_test, \n",
    "    test_base_unit_ohe.reset_index(drop=True)\n",
    "], axis=1).astype(np.float32).values \n",
    "\n",
    "\n",
    "# 3. PREPARE X_test COMPONENTS (No Full Concatenation)\n",
    "# This list is what you will use inside the prediction loop.\n",
    "X_test_components = [\n",
    "    X_simple_test_base,           # Simple features + OHE\n",
    "    final_text_features_test,     # Text features\n",
    "    test_image_features           # Image features (Must match what was used in training!)\n",
    "]\n",
    "\n",
    "# Save the original IDs for the submission file\n",
    "test_sample_ids = test_df['sample_id'].values \n",
    "\n",
    "print(f\"X_simple_test_base Shape: {X_simple_test_base.shape}\")\n",
    "print(f\"Total features (before TE) calculated: {sum(c.shape[1] for c in X_test_components)}\")\n",
    "print(\"Test components assembled for memory-safe prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0cef8-eb9f-469d-ac43-742ad8a15264",
   "metadata": {},
   "source": [
    "# Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f7adefb-98e9-4f18-9f5b-6496c01db055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting FINAL Prediction ---\n",
      "Final X_test Shape: (75000, 3209)\n",
      "Model 1 (Best Iteration: 2000) predictions generated.\n",
      "Model 2 (Best Iteration: 2000) predictions generated.\n",
      "Model 3 (Best Iteration: 1999) predictions generated.\n",
      "Model 4 (Best Iteration: 1999) predictions generated.\n",
      "Model 5 (Best Iteration: 2000) predictions generated.\n",
      "\n",
      "FINAL ENSEMBLE SUBMISSION CREATED!** File: test_out.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "required_rows = 75000\n",
    "test_predictions_list = []\n",
    "\n",
    "print(\"\\n--- Starting FINAL Prediction ---\")\n",
    "\n",
    "# --- 1. PREPARE X_TEST FINAL MATRIX (Leakage-Free Target Encoding) ---\n",
    "# Assuming X_test_components and test_sample_ids are defined from previous steps.\n",
    "\n",
    "# Calculate the Target Encoding feature for the entire test set\n",
    "# (using the full training set map)\n",
    "raw_names_train = train_df['item_name'] \n",
    "full_te_map = raw_names_train.map(pd.Series(y_train, index=raw_names_train.index)).groupby(raw_names_train).mean()\n",
    "test_names = test_df['item_name'] # Assuming test_df_raw is the base test df\n",
    "test_te_feature = test_names.map(full_te_map).fillna(train_log_price_mean).values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# FINAL X_test Matrix Assembly (Safe for LightGBM prediction)\n",
    "X_test_final = np.concatenate(X_test_components + [test_te_feature], axis=1)\n",
    "\n",
    "print(f\"Final X_test Shape: {X_test_final.shape}\")\n",
    "\n",
    "\n",
    "# --- 2. ENSEMBLE PREDICTION ---\n",
    "if len(final_models) == 5:\n",
    "    for i, fold_model in enumerate(final_models):\n",
    "        # ***MODIFICATION HERE: Use best_iteration***\n",
    "        log_preds = fold_model.predict(X_test_final, num_iteration=fold_model.best_iteration) \n",
    "        test_predictions_list.append(log_preds)\n",
    "        print(f\"Model {i+1} (Best Iteration: {fold_model.best_iteration}) predictions generated.\")\n",
    "\n",
    "    # 3. Average the log predictions (The Ensemble)\n",
    "    avg_log_preds = np.mean(np.array(test_predictions_list), axis=0)\n",
    "    \n",
    "    # 4. Inverse Transform and Non-Negative Constraint\n",
    "    test_final_predictions = np.expm1(avg_log_preds)\n",
    "    test_final_predictions[test_final_predictions < 0] = 0\n",
    "    \n",
    "    # --- 5. Save to Submission File ---\n",
    "    prediction_count = len(test_final_predictions)\n",
    "\n",
    "    if prediction_count == required_rows:\n",
    "        submission_df = pd.DataFrame({\n",
    "            # CRITICAL: Use 'sample_id' for the competition submission file\n",
    "            'sample_id': test_sample_ids,  \n",
    "            'price': test_final_predictions\n",
    "        })\n",
    "        submission_df.to_csv('test_out.csv', index=False)\n",
    "        print(\"\\nFINAL ENSEMBLE SUBMISSION CREATED!** File: test_out.csv\")\n",
    "    else:\n",
    "        print(f\"\\nCRITICAL FAILURE: Prediction count mismatch: {prediction_count}. Submission not saved.\")\n",
    "else:\n",
    "    print(f\"\\nError: Expected 1 model in final_models list, found {len(final_models)}. Cannot ensemble.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
